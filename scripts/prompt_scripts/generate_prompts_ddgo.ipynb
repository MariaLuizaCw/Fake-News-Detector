{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa49ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from importlib import reload\n",
    "\n",
    "MODULES_DIR = os.path.join(os.getcwd(), \"..\", \"..\", \"modules\")\n",
    "sys.path.append(os.path.abspath(MODULES_DIR))\n",
    "\n",
    "# 1. importe os módulos (não as funções)\n",
    "import prefilter_ner\n",
    "import embedder\n",
    "import help\n",
    "import prompt_builder\n",
    "\n",
    "# 2. recarregue apenas os módulos que você editou\n",
    "reload(prefilter_ner)\n",
    "reload(embedder)\n",
    "reload(help)\n",
    "reload(prompt_builder)\n",
    "\n",
    "# 3. agora sim importe as funções atualizadas\n",
    "from prefilter_ner import prefilter_results\n",
    "from embedder import HuggingFaceEmbedder\n",
    "from help import estimate_tokens\n",
    "from prompt_builder import build_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba47ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f94630",
   "metadata": {},
   "source": [
    "# Pre-filter ddgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2b16b",
   "metadata": {},
   "source": [
    "### Get retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d56cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = os.getenv(\"POSTGRES_USER\")\n",
    "PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "DB = os.getenv(\"POSTGRES_DB\")\n",
    "PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "\n",
    "# Criar engine SQLAlchemy\n",
    "engine = create_engine(f\"postgresql://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM retrieved_news_ddgo\", engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2217effa",
   "metadata": {},
   "source": [
    "### Filter Data by suffle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df[df['shuffle_id'].between(0, 1999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b42edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt['search_title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt.groupby('shuffle_id').size().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3d7ec",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4469bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class EntityComparator:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\", grouped=True):\n",
    "        \"\"\"\n",
    "        Inicializa o pipeline de NER.\n",
    "        \"\"\"\n",
    "        self.ner = pipeline(\n",
    "            \"ner\",\n",
    "            model=model_name,\n",
    "            grouped_entities=grouped\n",
    "        )\n",
    "\n",
    "    def extract_entities(self, text):\n",
    "        \"\"\"\n",
    "        Extrai entidades nomeadas como um conjunto de strings.\n",
    "        \"\"\"\n",
    "        ents = self.ner(text)\n",
    "        return {e[\"word\"] for e in ents}\n",
    "\n",
    "    def ner_score(self, ents1, ents2):\n",
    "        \"\"\"\n",
    "        Retorna score entre 0 e 1 baseado na fração de entidades de text1\n",
    "        que aparecem em text2.\n",
    "\n",
    "        Regra:\n",
    "        - score = interseção / total_entidades_text1\n",
    "        - se text1 não tiver entidades → score = 1\n",
    "        \"\"\"\n",
    "\n",
    "        # Caso especial\n",
    "        if len(ents1) == 0:\n",
    "            return {\n",
    "                \"score\": 1,\n",
    "                \"ents_text1\": [],\n",
    "                \"ents_text2\": [],\n",
    "                \"intersection\": []\n",
    "            }\n",
    "        \n",
    "        intersection = ents1.intersection(ents2)\n",
    "\n",
    "        score = len(intersection) / len(ents1)\n",
    "\n",
    "        return {\n",
    "            \"score\": score,\n",
    "            \"ents_text1\": list(ents1),\n",
    "            \"ents_text2\": list(ents2),\n",
    "            \"intersection\": list(intersection)\n",
    "        }\n",
    "\n",
    "cmp = EntityComparator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91b4f8",
   "metadata": {},
   "source": [
    "### Filter retrievel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c945263",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_x = 10  # número de top resultados que queremos\n",
    "\n",
    "summary_rows = []\n",
    "filtered_by_title = {}\n",
    "\n",
    "for idx, title in enumerate(df_filt['search_title'].unique()):\n",
    "    print(idx)\n",
    "    subset = df_filt[df_filt['search_title'] == title]\n",
    "    total_before = len(subset)\n",
    "    \n",
    "    subset = subset.drop_duplicates(subset=[\"original_title\"])\n",
    "    duplicates_removed = total_before - len(subset)\n",
    "    shuffle_id_val = subset[\"shuffle_id\"].iloc[0]\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            \"refined_title\": row[\"refined_title\"],\n",
    "            \"original_title\": row[\"original_title\"],\n",
    "            \"domain\": row[\"domain\"],\n",
    "            \"snippet\": row[\"snippet\"],\n",
    "            \"search_title\": row[\"search_title\"],\n",
    "            \"shuffle_id\": row[\"shuffle_id\"],\n",
    "        }\n",
    "        for _, row in subset.iterrows()\n",
    "    ]\n",
    "\n",
    "    # aplica filtro de similaridade\n",
    "    filtered_results = prefilter_results(\n",
    "        results=results,\n",
    "        original_title=title,\n",
    "        embedder=embedder,\n",
    "        credible_domains_file='../../out/credible_sources.txt'\n",
    "    )\n",
    "\n",
    "    ents1 = cmp.extract_entities(title)\n",
    "    for result in filtered_results:\n",
    "        ents2 = cmp.extract_entities(result['refined_title'])\n",
    "        details = cmp.ner_score(ents1, ents2)\n",
    "        result['query'] = title\n",
    "        result['NER_score'] = details['score']\n",
    "        result['NER_intersection'] = details['intersection']\n",
    "        result['ents_text1'] = details['ents_text1']\n",
    "        result['ents_text2'] = details['ents_text2']\n",
    "        result['NER_count'] = len(details['ents_text1'])\n",
    "\n",
    "    # contar removidos pelo filtro de similaridade\n",
    "    non_similar_removed = len(subset) - len(filtered_results)\n",
    "\n",
    "    # agora o total final após duplicatas + filtro de similaridade\n",
    "    totat_after = len(filtered_results)\n",
    "\n",
    "    # salva resultados filtrados\n",
    "    filtered_by_title[title] = filtered_results\n",
    "\n",
    "    # adiciona linha ao summary\n",
    "    summary_rows.append({\n",
    "        \"search_title\": title,\n",
    "        \"shuffle_id\": shuffle_id_val,\n",
    "        \"total_before\": total_before,\n",
    "        \"duplicates_removed\": duplicates_removed,\n",
    "        \"non_similar_removed\": non_similar_removed,\n",
    "        \"totat_after\": totat_after,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"resultados1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_by_title, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "alpha = 0.8\n",
    "beta  = 0.2\n",
    "\n",
    "final = {}\n",
    "\n",
    "for k,values in filtered_by_title.items():\n",
    "    for value in values:\n",
    "        value[\"score\"] = alpha*value[\"similarity\"] + beta*value[\"NER_score\"]\n",
    "\n",
    "    matched = values[:]\n",
    "    matched_085 = [item for item in values if item[\"score\"] >= 0.85]\n",
    "    matched_080 = [item for item in values if item[\"score\"] >= 0.80]\n",
    "    matched_070 = [item for item in values if item[\"score\"] >= 0.70]\n",
    "    \n",
    "    if matched_085: matched = matched_085[:]        \n",
    "    elif matched_080: matched = matched_080[:]\n",
    "    elif matched_070: matched = matched_070[:]\n",
    "\n",
    "    matched = sorted(matched, key=lambda x: x['score'], reverse=True)[:top_x]\n",
    "    final[k] = matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af570e9",
   "metadata": {},
   "source": [
    "## Build Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(filtered_by_title, mode='test1'):\n",
    "    rows = []\n",
    "    for title, filtered_results in filtered_by_title.items():\n",
    "\n",
    "        shuffle_id = filtered_results[0].get(\"shuffle_id\") if filtered_results else df_filt.set_index('search_title').to_dict()['shuffle_id'][title]\n",
    "\n",
    "        prompt = build_prompt(\n",
    "            mode=mode,\n",
    "            title_to_check=title,\n",
    "            results_filtered=filtered_results\n",
    "        )\n",
    "\n",
    "        info = {\n",
    "            \"search_title\": title,\n",
    "            \"shuffle_id\": shuffle_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"num_results\": len(filtered_results),\n",
    "            \"approx_tokens\": estimate_tokens(prompt),\n",
    "            \"prompt_length_chars\": len(prompt),\n",
    "        }\n",
    "        rows.append(info)\n",
    "\n",
    "    df_prompts = pd.DataFrame(rows)\n",
    "    return df_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = generate_prompts(final, mode=\"test1\")\n",
    "print(len(df_test1.search_title.unique()))\n",
    "df_test1.to_sql(\n",
    "    \"test_ner\",\n",
    "    engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "df_test1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
