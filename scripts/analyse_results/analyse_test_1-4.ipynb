{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18d4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "from importlib import reload\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7c1722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb49985",
   "metadata": {},
   "source": [
    "# Analysis TESTS: 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf2bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = os.getenv(\"POSTGRES_USER\")\n",
    "PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "DB = os.getenv(\"POSTGRES_DB\")\n",
    "PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "\n",
    "# Criar engine SQLAlchemy\n",
    "engine = create_engine(f\"postgresql://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d420c8e",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_sql(\"SELECT * FROM test1_results\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a23e0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "real    1048\n",
       "fake     952\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408d8c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\n"
     ]
    }
   ],
   "source": [
    "y_true = df_test1['true_class']\n",
    "y_pred = df_test1['response']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
    "cm_df = pd.DataFrame(cm, index=y_true.unique(), columns=y_true.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('LLM Output')\n",
    "plt.title('Test 1 - Confusion Matrix')\n",
    "plt.savefig(\"./test1/confusion_matrix.png\")  # Salva a figura como PNG\n",
    "plt.close()  # Fecha a figura para não mostrar\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"./test1/classification_report.csv\")\n",
    "\n",
    "print(\"✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fcfe4",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a20df7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.read_sql(\"SELECT * FROM test2_results\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07adf945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "real                        1168\n",
       "fake                         672\n",
       "real with misinformation     160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a630b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1249378/1092811253.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test2_1['response'].replace({'real with misinformation': 'fake'}, inplace=True)\n",
      "/tmp/ipykernel_1249378/1092811253.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test2_2['response'].replace({'real with misinformation': 'real'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## real with misinformation =  fake\n",
    "df_test2_1 = df_test2.copy()\n",
    "df_test2_1['response'].replace({'real with misinformation': 'fake'}, inplace=True)\n",
    "\n",
    "\n",
    "## real with misinformation =  real\n",
    "df_test2_2 = df_test2.copy()\n",
    "df_test2_2['response'].replace({'real with misinformation': 'real'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5ab6f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "real    1168\n",
       "fake     832\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2_1['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdc67ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "real    1328\n",
       "fake     672\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2_2['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1b8eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\n"
     ]
    }
   ],
   "source": [
    "y_true = df_test2_1['true_class']\n",
    "y_pred = df_test2_1['response']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
    "cm_df = pd.DataFrame(cm, index=y_true.unique(), columns=y_true.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('LLM Output')\n",
    "plt.title('Test 2 - Confusion Matrix (real with misinformation =  fake)')\n",
    "plt.savefig(\"./test2/confusion_matrix_(real with misinformation =  fake).png\")  # Salva a figura como PNG\n",
    "plt.close()  # Fecha a figura para não mostrar\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"./test2/classification_report_(real with misinformation =  fake).csv\")\n",
    "\n",
    "print(\"✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d77bd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\n"
     ]
    }
   ],
   "source": [
    "y_true = df_test2_2['true_class']\n",
    "y_pred = df_test2_2['response']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
    "cm_df = pd.DataFrame(cm, index=y_true.unique(), columns=y_true.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('LLM Output')\n",
    "plt.title('Test 2 - Confusion Matrix (real with misinformation =  real)')\n",
    "plt.savefig(\"./test2/confusion_matrix_(real with misinformation =  real).png\")  # Salva a figura como PNG\n",
    "plt.close()  # Fecha a figura para não mostrar\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"./test2/classification_report_(real with misinformation =  real).csv\")\n",
    "\n",
    "print(\"✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d18b84",
   "metadata": {},
   "source": [
    "## Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "590d9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3 = pd.read_sql(\"SELECT * FROM test3_results\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af854dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "fake    1080\n",
       "real     920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test3['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be6837dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\n"
     ]
    }
   ],
   "source": [
    "y_true = df_test3['true_class']\n",
    "y_pred = df_test3['response']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
    "cm_df = pd.DataFrame(cm, index=y_true.unique(), columns=y_true.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('LLM Output')\n",
    "plt.title('Test 3 - Confusion Matrix')\n",
    "plt.savefig(\"./test3/confusion_matrix.png\")  # Salva a figura como PNG\n",
    "plt.close()  # Fecha a figura para não mostrar\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"./test3/classification_report.csv\")\n",
    "\n",
    "print(\"✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a35b49",
   "metadata": {},
   "source": [
    "## Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9842e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test4 = pd.read_sql(\"SELECT * FROM test4_results\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a08cfc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e50ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1790e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "real    1143\n",
       "fake     857\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test4['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20f6e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\n"
     ]
    }
   ],
   "source": [
    "y_true = df_test4['true_class']\n",
    "y_pred = df_test4['response']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
    "cm_df = pd.DataFrame(cm, index=y_true.unique(), columns=y_true.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('LLM Output')\n",
    "plt.title('Test 4 - Confusion Matrix')\n",
    "plt.savefig(\"./test4/confusion_matrix.png\")  # Salva a figura como PNG\n",
    "plt.close()  # Fecha a figura para não mostrar\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"./test4/classification_report.csv\")\n",
    "\n",
    "print(\"✅ Confusion matrix e classification report salvos em arquivos CSV e PNG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
